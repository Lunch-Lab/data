{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 매장 -> 리뷰 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# url\n",
    "url = 'https://m.place.naver.com/restaurant/1085956231/review/visitor?entry=ple&reviewSort=recent'\n",
    "\n",
    "# Webdriver headless mode setting\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('window-size=1920x1080')\n",
    "options.add_argument(\"disable-gpu\")\n",
    "\n",
    "# BS4 setting for secondary access\n",
    "session = requests.Session()\n",
    "headers = {\n",
    "    \"User-Agent\": \"user value\"}\n",
    "\n",
    "retries = Retry(total=5,\n",
    "                backoff_factor=0.1,\n",
    "                status_forcelist=[500, 502, 503, 504])\n",
    "\n",
    "session.mount('http://', HTTPAdapter(max_retries=retries))\n",
    "\n",
    "# New xlsx file\n",
    "now = datetime.datetime.now()\n",
    "xlsx = Workbook()\n",
    "list_sheet = xlsx.create_sheet('output')\n",
    "list_sheet.append(['nickname', 'content', 'date', 'revisit'])\n",
    "\n",
    "# 유저 스크래핑 시작\n",
    "try:\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "    res = driver.get(url)\n",
    "    driver.implicitly_wait(30)\n",
    "\n",
    "    # Pagedown\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            driver.find_element(By.XPATH, '//*[@id=\"app-root\"]/div/div/div/div[6]/div[2]/div[3]/div[2]/div/a').click()\n",
    "            time.sleep(0.4)\n",
    "    except Exception as e:\n",
    "        print('finish')\n",
    "\n",
    "    time.sleep(25)\n",
    "    html = driver.page_source\n",
    "    bs = BeautifulSoup(html, 'lxml')\n",
    "    reviews = bs.select('li.YeINN')\n",
    "\n",
    "    for r in reviews:\n",
    "        nickname = r.select_one('div.VYGLG')\n",
    "        content = r.select_one('div.ZZ4OK.IwhtZ')\n",
    "        date = r.select('div._7kR3e>span.tzZTd>time')[0]\n",
    "        revisit = r.select('div._7kR3e>span.tzZTd')[1]\n",
    "\n",
    "        # exception handling\n",
    "        nickname = nickname.text if nickname else ''\n",
    "        content = content.text if content else ''\n",
    "        date = date.text if date else ''\n",
    "        revisit = revisit.text if revisit else ''\n",
    "        time.sleep(0.06)\n",
    "\n",
    "        print(nickname, '/', content, '/', date, '/', revisit)\n",
    "        list_sheet.append([nickname, content, date, revisit])\n",
    "        time.sleep(0.06)\n",
    "    # Save the file\n",
    "    file_name = 'naver_review_' + now.strftime('%Y-%m-%d_%H-%M-%S') + '.xlsx'\n",
    "    xlsx.save(file_name)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # Save the file(temp)\n",
    "    file_name = 'naver_review_' + now.strftime('%Y-%m-%d_%H-%M-%S') + '.xlsx'\n",
    "    xlsx.save(file_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
