{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 매장 -> 매장에 있는 review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import requests\n",
    "from openpyxl import Workbook\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규 표현식으로 이모티콘, 특수문자 제거 (단, ?와 !는 제외)\n",
    "def remove_special_characters(text):\n",
    "    pattern = r'[^\\w\\s!?]|_'\n",
    "    result = re.sub(pattern, '', text)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "original_res_df = pd.read_excel('combined_file.xlsx')\n",
    "original_df = original_res_df.copy()\n",
    "original_df = original_df.loc[original_df['검색여부'] == '가능'].reset_index(drop=True)\n",
    "original_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# 컬럼 순서 바꾸기 -> 보기 좋으라고 바꿈\n",
    "original_df['검색어'] = original_df['상세주소'] + \" \" + original_df['사업장명']\n",
    "column_order = ['검색어', '업태구분명', '사업장명', '사업장명_원본', '시도', '지역구', '상세주소', '소재지전체주소', '도로명전체주소', '좌표정보(x)', '좌표정보(y)', '검색여부', '영업상태명']\n",
    "original_df = original_df[column_order]\n",
    "original_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 리뷰 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_num = 0 # 할 차례\n",
    "num = 2\n",
    "end_num = start_num + num\n",
    "res_df = original_df[start_num:end_num]\n",
    "new_res_df_test = res_df.reset_index(drop=True)\n",
    "new_res_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 음식점 리뷰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈 리스트 생성\n",
    "user_id_list = []\n",
    "content_list = []\n",
    "date_list = []  \n",
    "revisit_list = []\n",
    "tag_category_name_list = []\n",
    "restaurant_name_list = []\n",
    "review_category_name_list = []\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "scroll_num = 5\n",
    "\n",
    "for i in range(0,len(new_res_df_test)):\n",
    "  \n",
    "    name = new_res_df_test['검색어'][i]\n",
    "    driver.get('https://map.naver.com/p/search/{}'.format(name))\n",
    "\n",
    "    time.sleep(3)  \n",
    "    try :\n",
    "        if driver.find_elements(By.ID,'entryIframe') :\n",
    "            entryIframe = driver.find_element(By.ID,'entryIframe')\n",
    "            driver.switch_to.frame(entryIframe)\n",
    "    except :\n",
    "        pass \n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    try : \n",
    "        # '리뷰' 탭의 href 속성 가져오기\n",
    "        review_tab_href = soup.find('a', {'class': 'tpj9w _tab-menu', 'aria-selected': 'true'}).get('href')\n",
    "        review_url = 'https://pcmap.place.naver.com'+review_tab_href\n",
    "\n",
    "        driver.get(review_url)\n",
    "        time.sleep(2.2)  \n",
    "\n",
    "    except :\n",
    "        print('끝')\n",
    "\n",
    "    # 현재 페이지 URL 가져오기\n",
    "    current_url = driver.current_url\n",
    "\n",
    "    try : \n",
    "        # 리뷰 url로 이동 \n",
    "        modified_url = current_url.replace('/home', '/review/visitor')\n",
    "        driver.get(modified_url)\n",
    "    except :\n",
    "        continue\n",
    "\n",
    "    # 리뷰 스크래핑 시작\n",
    "    try:\n",
    "        # 스크롤\n",
    "        for _ in range(scroll_num):\n",
    "            current_scroll_position = driver.execute_script('return window.scrollY;') # 초기 스크롤 위치 \n",
    "\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2) \n",
    "            \n",
    "            # 'TeItc' 클래스를 가진 요소가 클릭 가능할 때까지 기다리고, 보이도록 스크롤\n",
    "            button = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CLASS_NAME, 'TeItc')))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "            button.click()\n",
    "\n",
    "            # 더보기 클릭\n",
    "            button = driver.find_element_by_class_name('fvwqf')\n",
    "            button.click()\n",
    "\n",
    "            # 'fvwqf' 클래스를 가진 요소가 나타날 때까지 스크롤\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", button)\n",
    "            button.click()\n",
    "\n",
    "            # ------------ 리뷰, 태그 '내용 더보기' 버튼 클릭 ----------------------\n",
    "            review_buttons = driver.find_elements_by_class_name('xHaT3')  \n",
    "            for button1 in review_buttons:\n",
    "                try:\n",
    "                    button1.click()\n",
    "                except :\n",
    "                    pass\n",
    "\n",
    "            tag_buttons = driver.find_elements_by_css_selector('.gyAGI a.P1zUJ.ZGKcF')  \n",
    "            for button2 in tag_buttons:\n",
    "                try:\n",
    "                    button2.click()\n",
    "                except :\n",
    "                    pass\n",
    "            # ----------------------------------------------\n",
    "            time.sleep(3)\n",
    "\n",
    "            # ---------------스크롤위치가 변하지 않으면 리뷰를 다 크롤링한 것이니까 탈출 -------------------------\n",
    "            # 현재 스크롤 \n",
    "            new_scroll_position = driver.execute_script('return window.scrollY;')\n",
    "\n",
    "            # 현재 위치와 이전 위치가 같으면 반복문 탈출\n",
    "            if new_scroll_position == current_scroll_position:\n",
    "                break\n",
    "\n",
    "            # 이전 스크롤 위치 업데이트\n",
    "            prev_scroll_position = current_scroll_position\n",
    "            # -------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "            reviews = soup.select('li.owAeM') \n",
    "\n",
    "        # 리뷰 크롤링 시작\n",
    "        for r in reviews:\n",
    "            user_id = r.select_one('div.qgLL3 span.P9EZi')\n",
    "            review_count = r.select_one('div.Gt2_9 span.RNn6x:nth-of-type(1)')\n",
    "            photo_count = r.select_one('div.Gt2_9 span.RNn6x:nth-of-type(2)')\n",
    "            \n",
    "            content = r.select_one('div.vg7Fp span.zPfVt')\n",
    "            \n",
    "            try:\n",
    "                tag = r.select_one('div.ERkm0 span.sIv5s')\n",
    "            except:\n",
    "                tag = \"\"\n",
    "            \n",
    "            date = r.select_one('div.jxc2b div.D40bm span.CKUdu time')\n",
    "            revisit = r.select_one('div.jxc2b div.D40bm span.CKUdu:nth-of-type(2)')\n",
    "            \n",
    "            # 없는 경우 \n",
    "            user_id_text = user_id.text if user_id else ''\n",
    "            review_count_text = review_count.text if review_count else ''\n",
    "            photo_count_text = photo_count.text if photo_count else ''\n",
    "            content_text = content.text if content else ''\n",
    "            tag_text = tag.text if tag else ''\n",
    "            date_text = date.text if date else ''\n",
    "            revisit_text = revisit.text.replace('번째 방문', '') if revisit else ''\n",
    "            \n",
    "            # 리스트에 합치기\n",
    "            restaurant_name_list.append(name)\n",
    "            user_id_list.append(user_id_text)\n",
    "            review_category_name_list.append(tag_text)\n",
    "            date_list.append(date_text)\n",
    "            revisit_list.append(revisit_text)\n",
    "            content_list.append(remove_special_characters(content_text))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "# 데이터프레임 얹히기\n",
    "review_data_list = {\n",
    "    '검색어': restaurant_name_list,\n",
    "    'user_id': user_id_list,\n",
    "    'review': content_list,\n",
    "    'date': date_list,\n",
    "    'revisit': revisit_list,\n",
    "    'tag': review_category_name_list\n",
    "}\n",
    "\n",
    "# 리뷰 데이터 프레임 완성\n",
    "review_result_df = pd.DataFrame(review_data_list)\n",
    "\n",
    "review_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_result_df.to_excel(f'./data/restaurant_review_data/restaurant_review_df_{start_num}_{end_num}.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_result_df.to_excel('.data/음식점_리뷰데이터.xlsx')\n",
    "# tag_result_df.to_excel('.data/음식점_태그데이터.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    # 정규 표현식으로 이모티콘, 특수문자, 아스키코드 제거 (단, ?와 !는 제외)\n",
    "    pattern = r'[^\\w\\s!?]|_'\n",
    "    result = re.sub(pattern, '', text)\n",
    "    return result\n",
    "\n",
    "\n",
    "text = \"Hello, World! 😊 How are you today??????!!!? #Python\"\n",
    "result = remove_special_characters(text)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
